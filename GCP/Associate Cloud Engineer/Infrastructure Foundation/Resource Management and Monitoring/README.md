<br>
<br>

# **Infrastructure Foundation: Resource Management and Monitoringüìö‚òÅÔ∏è**

---

<br>

Means controlling cost. Quotas that limit consumption and can be raised on request. Billing to set budgets and alerts. Resource management let's you manage resources hierarchically by folder, project and organization. Policies contain a set of
roles and members that are set on resources. These are inherited and if a parent policy is less restrictive, it overrides the more restrictive resource policy. Child policies cannot restrict access granted at parent level. IAM policies are
inherited from top to bottom, but billing is accumulated from bottom up. Resource consumption is measured in quantities like rate of use, number of items or feature use. Because a resource just belongs to one project, the project accumulates the
consumption of all its resources. A project is associated with one billing account, and an organization contains all billing accounts.
Organization Admin delegates privileges and access to individual projects to Project Creator. A project accumulates the consumption of its resources, it can be used to track resources and quota usage. Projects where billing is enabled, permissions are
managed, and services and API are enables, can track resource and quota usage. To interact with GCP resources, you must provide the project identifying information for every request. The project name is human-readalbe way to identify projects though
is not used by API; project ID generated unique; and project number automatically generated by server.
Resources are categorized as regional (External IP addresses), zonal (instances and disks) or global (images, snapshots, networks). Regardless into type, each resources is organzied into a project (logical instead of physical organization). Billing
and reporting is done per project.

<br>

---

<br>

## **Quotas**

All resources are subject to project quotas or limits. They are part of one of three categories:

- Resources per project (15VPC networks per project)
- API request rate in project (5 admin actions per second on Cloud Spanner)
- Resources per region (24 CPUs per region)

Even though we have these quotes, GCP allows to exand over time and increase accordingly to your usage. In case of an upcoming increase in usage, you can proactively request quota adjustments in Cloud Console. Even though they can be changes,t hey exist to
avoid runaway consumption in case of malicious or error attack (1). A quota might also prevent billing spikes (2) in case of creating 100 instances instead of 10 due to a typo. These are not the same as budget alerts. They are also used to force sizing
considerations and periodic review to go for cheaper alternatives (3).
Note that quotas limit the amount of resources that can be created but they do not guarantee that resources will be available.

<br>

---

<br>

## **Labels**

Allows more granularity for segregating and organizing resources. They can be attached to resources with Console, gcloud or API. Can be used to define the environment of the VM (test or dev) so we can search and list all production resources
for inventory purposes. They can also be used in scripts to help analyze costs or run bulk operations on multiple resources.
It is recommended adding labels based on teams or cost center (team: marketing, research, etc.) to distinguish components (component: frontend, redis, etc.), or environments (environment: prod, test, etc.). Can also be used to define the owner or primary contract for a
resource (owner: gaurav, contact: opm, etc.), or even the state of the resource (state:in-use, ready-for-deletion, etc.).
It is key to distinguish them from tags. Labels are user-defined strings in key-value format used to organize resources that are propagated through billing. On the other side, tags are user-defined strings applied to instances that are primarily
used for networking like applying firewall rules.

<br>

---

<br>

## **Billing**

All resources under one project accumulate into one billing account. To help project planning and controlling costs, you can set a budget that lets you track your spend growth towards an amount. For setting a budget, first you select a name, and choose
the projects to which they apply. Later, you set the budget at a specific amount of set it to previous month spend. Afterwards, you can set alerts that send emails to Billing Admins after the spend exceeds a percentage or specified amount of the budget. By default, it
will be sent at 50, 90 and 100%. Can also send an alertt when the send is forecasted to exceed the % of the budget amount by the end of the budget period.
Can use Pub/Sub to programatically receive spend updates about this budget. Can create a Cloud Function that listens to the PubSub topic and automates cost management.
The mail contains the project name, % of budget exceeded, and budget amount. Can also use labels to help optimize spend (instances across different regions incur in higher costs, so might consider relocating some instances or using caching service like Cloud CDN and
therefoe reduce networking traffic).
It is recommended to label all resources and exporting billing data to BigQuery to analyze spend. It is easy to create queries, and can also visualize spend over time with Data Studio.

<br>
<br>

# **Resource Monitoring**

## **GCP Operations Suite**

Stackdriver dynamically discovers cloud resources and apps based on deep integration with GCP and AWS. Access to powerful data and analytics tools plus third-party providers. Has services for monitoring, logging, error reporting, fault tracing and debugging.
You pay for what you use with free usage allotments. It works in a single, comprhensive and integrated service. To create reliable, stable and mantainable applications, Stackdriver supports a rich and growing ecosystem. Helps expand the IT Ops, security, compliance
capabilities to GCP customers. There are multiple integrations with third-party software providers.

<br>

---

<br>

## **Cloud Monitoring**

Important because it is at the base of SRE (Site Reliability Enginereeing). It applies software engineering to operations to create ultra scalable and highly reliable systems. It has enabled Google to build, deploy, monitor and mantain larg ecosystems. Stackdriver
dynamically configures monitoring after resources are deployed, and has intelligent defaults that allow to create charts for basic monitoring allowing to monitor your platflow, system and application metrics by ingesting data such as events, metrics and metadata.
You can generate insights with data through dashboards, charts and alerts. A workspace is the root entity that holds monitoring and information in Stackdriver monitoring. Can have between 1 and 100 monitored projects, and can hav as many workspaces as you want.
A workspace can access data from monitored projects, but the log entries remain in individual projects. The first monitor project is called hosting project and the name of the name becomes the name of the workspace. Allows to monitor all GCP projects in a single
place. There is an AWS connector to monitor AWS accounts. Stackdriver role assigned to one person on one project applies equally to all projects monitored by that workspace. So to give people different roles per different projects and to control visibility of data,
it is recommended to place the monitoring of projects in different workspaces.
Cloud Monitoring allows to create custom charts of metrics we want to control. They provide visibility into the utilization and network traffic. We can apply filters, remove noice, aggregate, etc. They can only provide insights in case someone is looking at them. In case
there is anyone, we mst create alerting policies that notify you in case some conditions are met. Can be notifies through email, SMS or other channels. Can create alerts when you approach the threshold for billing. Recommend alerting on symptoms and not causes, so for
example we might want to get notified for failing queries in a DB and later identify whether the DB is down, or there is another major issue. This avoids a single point of failure in alerting strategy. It is also recommended to customize alerts depending on the audience,
explaining the resources and actions to be taken. Also, avoid noise because this will cause alerts to be dismissed over time. Adjust them so they are actionable and not set it on everything possible.
Can create uptime checks that test the availability of public services. An HTTP check have a certain timeout, and are considered failures if no response is obtained in this period. You can also install a monitoring agent (CPU utilization, disk traffic, etc.). To access
additional resources and services this agent is recommended. It is supported by Compute Engine and EC2 instances.
If default metric provided by Stackdriver do not fit your needs, you can create your custom ones.

<br>

---

<br>

## **Logging**

Allows to store, analyze and search log data from GCP and AWS. Fully managed service that performs at scale and ingests app and system log data from thousands of VMs. Logging includes storage for logs, a GUI called the log viewer, and an API to manage logs programatically.
Lets you read and write log entries, seach, filter and create log-based metrics.
They are only retained for 30 days but they can be exported to GCS buckets, PubSub or BigQuery datasets. Exporting logs to Cloud Storage makes sense for more than 30 days. BigQuery allows to analize logs and even visualize them in Data Studio. It runs fast SQL queries on
GBs to PBs of data. Can better understand traffic growth for forecast capacity. Network usage to optimize traffic expenses (depending on IP addresses) or forensics to analyze incidents. Can visualize them with Data Studio and can convert raw data into metrics and dimensions
so can create reports. With ubSub, can stream logs to applications or end points. Like Stackdriver Monitoring agent, it is best practice to install the logging agent to all VM instances. Supported in Compute Engine and EC2 instances.

<br>

---

<br>

## **Error Reporting**

Counts, analyzes and aggregates the errors in Cloud services. There is a centralized error management interface that displays the results with sorting and filtering capabilities. You can set up real-time notifications when errors are detected. The exceptuon stack trace parser
is able to be processed in Go, Java, Node.js, PHP, Python and Ruby. Error reporting is able for App Engine Standard and beta for flexible, Compute Engine, Cloud Functions and EC2.

<br>

---

<br>

## **Tracing**

Integrated into GCP and important for overall performance to manage the timings of the apps to handle incoming requests and perform operations. Distributed tracing system:

- Collects latency data from apps and displays it in the console.
- Can track how requests propagate through your applications and receive detailes near real-time performance insights.
- Per-URL latency sampling

It automatically analyzes all app traces to generate depth latency reports from performance degradations from App Engine, HTTPS load balancers, and apps instrumented with Cloud Trace SDKs (Stackdriver Trace API).

<br>

---

<br>

## **Debugging**

Feature of GCP that allows to inspect the state of the running application in real time without stopping or slowing it down. The debugger adds less than 10ms to the request latency when the state is captured (not noticeable by users). This feature allows to understand the behavior of code
in production and analyze its state to locate hard to find bugs. With few clicks, can take a snapshot of running applications state (call stack and local variables), or inject a new logging statement (debug logpoints). It supports multiple languages like Java, Python, Go, Node.js or Ruby.
